{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n1.\tADI: adipose tissue, consists of adipocytes\n2.\tBACK: background of histopathological images\n3.\tDEB: debris, usefull for diagnosis of cancer\n4.\tLYM: lymphocytes, cells of lymphatic system\n5.\tMUC: mucus, protective layer on tissue\n6.\tMUS: smooth muscle\n7.\tNORM: normal tissue of colon\n8.\tSTR: stroma tissue associated with cancer\n9.\tTUM: epithelium tissues of adenocarcinoma\n","metadata":{"_uuid":"b95e0566-534d-4d71-b5d8-ff9d08272ba0","_cell_guid":"edef3af9-2ade-48e2-9041-af04580ad02c"}},{"cell_type":"markdown","source":"credit: based on the [nct/crc notebook](https://www.kaggle.com/code/hosseindaqiqi/diagnosing-colon-cancer-using-transfer-learning?scriptVersionId=92363738) by [mayson](https://www.kaggle.com/hosseindaqiqi)","metadata":{}},{"cell_type":"code","source":"# Imports\nimport os, warnings, cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\n\nfrom os import listdir\nfrom os.path import isfile, join\nfrom shutil import rmtree\n\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.callbacks import ModelCheckpoint,  ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Flatten\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.datasets import make_classification","metadata":{"_uuid":"1e581559-cc00-4f44-903d-918791ae1741","_cell_guid":"058dc093-474d-4ba2-86f7-f7bba0706b88","execution":{"iopub.status.busy":"2023-08-22T14:46:49.787498Z","iopub.execute_input":"2023-08-22T14:46:49.787911Z","iopub.status.idle":"2023-08-22T14:46:49.795743Z","shell.execute_reply.started":"2023-08-22T14:46:49.787877Z","shell.execute_reply":"2023-08-22T14:46:49.794712Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"#sanity check tf\nprint(tf.__version__)\n#sanity check gpus on system\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    print(gpu)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T14:46:49.798016Z","iopub.execute_input":"2023-08-22T14:46:49.798708Z","iopub.status.idle":"2023-08-22T14:46:49.809012Z","shell.execute_reply.started":"2023-08-22T14:46:49.798661Z","shell.execute_reply":"2023-08-22T14:46:49.807810Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"2.12.0\nPhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n","output_type":"stream"}]},{"cell_type":"code","source":"#Load the directory\nmain_path = '../input/nct-crc-he-100k/NCT-CRC-HE-100K'\nsub_dir =os.listdir(main_path)","metadata":{"_uuid":"05ebb751-0b60-4af2-806d-3fa03f5bf708","_cell_guid":"3fbca759-9469-43d9-afc5-2e0c3c64b98c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-22T14:46:49.810760Z","iopub.execute_input":"2023-08-22T14:46:49.811108Z","iopub.status.idle":"2023-08-22T14:46:49.824023Z","shell.execute_reply.started":"2023-08-22T14:46:49.811075Z","shell.execute_reply":"2023-08-22T14:46:49.823024Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"#Creat The DataFrame\nData_df=pd.DataFrame({'ID': [], 'Class':[]})\n\nfor subdir in sub_dir:\n    mypath = join(main_path,subdir)\n    files=[f for f in listdir(mypath)]\n    classes=[subdir for c in files]\n    files_df = pd.DataFrame({'ID':files, 'Class':classes})\n    Data_df = Data_df.append(files_df)\n\nData_df['Old_class'] = Data_df['Class']\n#merge classes for our setting\nData_df['Class'] = Data_df['Class'].apply(lambda x: 1 if x in ['TUM'] else 0)\nData_df","metadata":{"_uuid":"e8d9355f-d613-4850-9d16-0c1aee70194f","_cell_guid":"0a980a2b-282d-4218-a319-6a97cf9316a8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-22T14:46:49.827043Z","iopub.execute_input":"2023-08-22T14:46:49.827451Z","iopub.status.idle":"2023-08-22T14:46:49.996613Z","shell.execute_reply.started":"2023-08-22T14:46:49.827416Z","shell.execute_reply":"2023-08-22T14:46:49.995622Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n/tmp/ipykernel_28/2885684629.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  Data_df = Data_df.append(files_df)\n","output_type":"stream"},{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"                     ID  Class Old_class\n0      MUC-GQLYEALK.tif      0       MUC\n1      MUC-FYTGWFGD.tif      0       MUC\n2      MUC-AVNDTFWS.tif      0       MUC\n3      MUC-DQPFGFLS.tif      0       MUC\n4      MUC-FNEDYLHG.tif      0       MUC\n...                 ...    ...       ...\n10441  STR-NQFCFNPH.tif      0       STR\n10442  STR-KPWLGGCI.tif      0       STR\n10443  STR-FFCLCFPE.tif      0       STR\n10444  STR-HGPELQKY.tif      0       STR\n10445  STR-KSMCARID.tif      0       STR\n\n[100000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Class</th>\n      <th>Old_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MUC-GQLYEALK.tif</td>\n      <td>0</td>\n      <td>MUC</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MUC-FYTGWFGD.tif</td>\n      <td>0</td>\n      <td>MUC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MUC-AVNDTFWS.tif</td>\n      <td>0</td>\n      <td>MUC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MUC-DQPFGFLS.tif</td>\n      <td>0</td>\n      <td>MUC</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MUC-FNEDYLHG.tif</td>\n      <td>0</td>\n      <td>MUC</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10441</th>\n      <td>STR-NQFCFNPH.tif</td>\n      <td>0</td>\n      <td>STR</td>\n    </tr>\n    <tr>\n      <th>10442</th>\n      <td>STR-KPWLGGCI.tif</td>\n      <td>0</td>\n      <td>STR</td>\n    </tr>\n    <tr>\n      <th>10443</th>\n      <td>STR-FFCLCFPE.tif</td>\n      <td>0</td>\n      <td>STR</td>\n    </tr>\n    <tr>\n      <th>10444</th>\n      <td>STR-HGPELQKY.tif</td>\n      <td>0</td>\n      <td>STR</td>\n    </tr>\n    <tr>\n      <th>10445</th>\n      <td>STR-KSMCARID.tif</td>\n      <td>0</td>\n      <td>STR</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Distribution of the Classes\nclass_of_patch = Data_df.Class.value_counts()\nprint('Distribution of classes is as followed:\\n{}'.format(class_of_patch[::-1]),'\\n','\\n')","metadata":{"_uuid":"b57e72d3-0c1b-4142-a879-7c670b513388","_cell_guid":"caadd03c-b81b-4038-b06f-e91a35772084","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-22T14:46:49.998113Z","iopub.execute_input":"2023-08-22T14:46:49.998999Z","iopub.status.idle":"2023-08-22T14:46:50.009291Z","shell.execute_reply.started":"2023-08-22T14:46:49.998961Z","shell.execute_reply":"2023-08-22T14:46:50.008073Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Distribution of classes is as followed:\n1    14317\n0    85683\nName: Class, dtype: int64 \n \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# split data ","metadata":{"_uuid":"00aa6867-40b8-421b-b461-61e1d319164d","_cell_guid":"d67f7b0d-8f0d-4933-b592-046e941f6e59","trusted":true}},{"cell_type":"code","source":"# split validation and training data\ny_1 = Data_df['Class']\n\ntrain_test_df, val_df = train_test_split(Data_df,train_size = 0.85,random_state=101,shuffle=True,stratify=y_1 ) \n\ny_2 = train_test_df['Class']\n\ntrain_df, test_df = train_test_split(train_test_df,train_size=0.823529,random_state=101,shuffle=True,stratify=y_2)","metadata":{"_uuid":"04c12fbb-9581-4002-98de-2ff0f275972c","_cell_guid":"4538b04c-4c75-42bf-b55c-ffa8755596d3","execution":{"iopub.status.busy":"2023-08-22T14:46:50.012336Z","iopub.execute_input":"2023-08-22T14:46:50.012862Z","iopub.status.idle":"2023-08-22T14:46:50.110648Z","shell.execute_reply.started":"2023-08-22T14:46:50.012834Z","shell.execute_reply":"2023-08-22T14:46:50.109559Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"#check the distribution of data in training and validation sets\nclass_of_train_patch = train_df.Class.value_counts()\nclass_of_val_patch = val_df.Class.value_counts()\nclass_of_test_patch = test_df.Class.value_counts()\n\nprint('Class Distribution of Training Examples:\\n{}'.format(class_of_train_patch),'\\n','\\n','\\n','\\n')\nprint('Class Distribution of Validation Examples:\\n{}'.format(class_of_val_patch),'\\n','\\n','\\n','\\n')\nprint('Class Distribution of Test Examples:\\n{}'.format(class_of_test_patch),'\\n','\\n','\\n','\\n')","metadata":{"_uuid":"b8fd64df-113c-43d1-801f-785ab59ae23d","_cell_guid":"c8ab9782-26e1-44f4-8d9c-d33cf5cdd59e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-22T14:46:50.112368Z","iopub.execute_input":"2023-08-22T14:46:50.112757Z","iopub.status.idle":"2023-08-22T14:46:50.128982Z","shell.execute_reply.started":"2023-08-22T14:46:50.112720Z","shell.execute_reply":"2023-08-22T14:46:50.127852Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Class Distribution of Training Examples:\n0    59978\n1    10021\nName: Class, dtype: int64 \n \n \n \n\nClass Distribution of Validation Examples:\n0    12852\n1     2148\nName: Class, dtype: int64 \n \n \n \n\nClass Distribution of Test Examples:\n0    12853\n1     2148\nName: Class, dtype: int64 \n \n \n \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## write splits to local filesystem","metadata":{"_uuid":"04dcb570-f668-4eeb-aa30-a485700fbd0a","_cell_guid":"24de03e6-e520-40ce-aee9-878724b6b5bf","trusted":true}},{"cell_type":"code","source":"\"\"\"\nmain_dir = 'SplittedData'\nos.mkdir(main_dir)\n\ntrain_dir = join(main_dir,'Training')\nos.mkdir(train_dir)\n\nval_dir = join(main_dir,'Validation')\nos.mkdir(val_dir)\n\ntest_dir = join(main_dir,'Test')\nos.mkdir(test_dir)\n\n\nfor subdir in [\"0\", \"1\"]:\n    train_sub_dir = join(train_dir,subdir)\n    os.mkdir(train_sub_dir)\n    \n    val_sub_dir = join(val_dir,subdir)\n    os.mkdir(val_sub_dir)\n    \n    test_sub_dir = join(test_dir,subdir)\n    os.mkdir(test_sub_dir)\n\"\"\"","metadata":{"_uuid":"5b1923f5-5200-4e0d-aa1c-b25ebdbd8e49","_cell_guid":"fdd17dd8-01ea-4a20-a619-a79f585d66b2","execution":{"iopub.status.busy":"2023-08-22T14:46:50.132552Z","iopub.execute_input":"2023-08-22T14:46:50.135688Z","iopub.status.idle":"2023-08-22T14:46:50.146249Z","shell.execute_reply.started":"2023-08-22T14:46:50.135640Z","shell.execute_reply":"2023-08-22T14:46:50.143656Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"'\\nmain_dir = \\'SplittedData\\'\\nos.mkdir(main_dir)\\n\\ntrain_dir = join(main_dir,\\'Training\\')\\nos.mkdir(train_dir)\\n\\nval_dir = join(main_dir,\\'Validation\\')\\nos.mkdir(val_dir)\\n\\ntest_dir = join(main_dir,\\'Test\\')\\nos.mkdir(test_dir)\\n\\n\\nfor subdir in [\"0\", \"1\"]:\\n    train_sub_dir = join(train_dir,subdir)\\n    os.mkdir(train_sub_dir)\\n    \\n    val_sub_dir = join(val_dir,subdir)\\n    os.mkdir(val_sub_dir)\\n    \\n    test_sub_dir = join(test_dir,subdir)\\n    os.mkdir(test_sub_dir)\\n'"},"metadata":{}}]},{"cell_type":"code","source":"main_dir = 'SplittedData'\n\ntrain_dir = join(main_dir,'Training')\n\nval_dir = join(main_dir,'Validation')\n\ntest_dir = join(main_dir,'Test')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-22T14:46:50.151732Z","iopub.execute_input":"2023-08-22T14:46:50.152401Z","iopub.status.idle":"2023-08-22T14:46:50.157943Z","shell.execute_reply.started":"2023-08-22T14:46:50.152359Z","shell.execute_reply":"2023-08-22T14:46:50.156942Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nData_df.set_index('ID', inplace=True)\n\nfor img in train_df['ID']:\n    label_old = Data_df.loc[img,'Old_class']\n    label_new = Data_df.loc[img,'Class']\n    source = join(main_path,label_old,img)\n    dest = join(train_dir,str(label_new),img)\n    \n    cv2_img = cv2.imread(source)\n    cv2.imwrite(dest,cv2_img)\n\n    \nfor img in val_df['ID']:\n    label_old = Data_df.loc[img,'Old_class']\n    label_new = Data_df.loc[img,'Class']\n    source = join(main_path,label_old,img)\n    dest = join(val_dir,str(label_new),img)\n    \n    cv2_img = cv2.imread(source)\n    cv2.imwrite(dest,cv2_img)\n\n    \nfor img in test_df['ID']:\n    label_old = Data_df.loc[img,'Old_class']\n    label_new = Data_df.loc[img,'Class']\n    source = join(main_path,label_old,img)\n    dest = join(test_dir,str(label_new),img)\n    \n    cv2_img = cv2.imread(source)\n    cv2.imwrite(dest,cv2_img)\n\"\"\"","metadata":{"_uuid":"d3874d4a-2a4b-4e41-8a9c-343572e44197","_cell_guid":"bbe7a3d7-3192-4cdb-9f1f-dcf8219f45dd","execution":{"iopub.status.busy":"2023-08-22T14:46:50.159326Z","iopub.execute_input":"2023-08-22T14:46:50.160211Z","iopub.status.idle":"2023-08-22T14:46:50.173090Z","shell.execute_reply.started":"2023-08-22T14:46:50.160166Z","shell.execute_reply":"2023-08-22T14:46:50.172024Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"\"\\nData_df.set_index('ID', inplace=True)\\n\\nfor img in train_df['ID']:\\n    label_old = Data_df.loc[img,'Old_class']\\n    label_new = Data_df.loc[img,'Class']\\n    source = join(main_path,label_old,img)\\n    dest = join(train_dir,str(label_new),img)\\n    \\n    cv2_img = cv2.imread(source)\\n    cv2.imwrite(dest,cv2_img)\\n\\n    \\nfor img in val_df['ID']:\\n    label_old = Data_df.loc[img,'Old_class']\\n    label_new = Data_df.loc[img,'Class']\\n    source = join(main_path,label_old,img)\\n    dest = join(val_dir,str(label_new),img)\\n    \\n    cv2_img = cv2.imread(source)\\n    cv2.imwrite(dest,cv2_img)\\n\\n    \\nfor img in test_df['ID']:\\n    label_old = Data_df.loc[img,'Old_class']\\n    label_new = Data_df.loc[img,'Class']\\n    source = join(main_path,label_old,img)\\n    dest = join(test_dir,str(label_new),img)\\n    \\n    cv2_img = cv2.imread(source)\\n    cv2.imwrite(dest,cv2_img)\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"# data loaders using keras flow from dir","metadata":{"_uuid":"d7fd4bbb-ca98-40ca-934e-7be981dd7d26","_cell_guid":"141a8b0a-9cac-458c-9b07-edd21302d16a","trusted":true}},{"cell_type":"code","source":"img_size = 224\nimg_channel=3\ninput_shape=(img_size,img_size,img_channel)\nBATCH_size =1024\nlearning_rate = 3E-4\ntrain_step = (len(train_df)/BATCH_size)\nval_step = (len(val_df)/BATCH_size)\n\n#datagen = ImageDataGenerator(rescale=1.0/255)\ndatagen = ImageDataGenerator()\n\n#turn shuffle off for train\ntrain_ds= datagen.flow_from_directory(train_dir,\n                                     target_size=(img_size,img_size),\n                                     batch_size=BATCH_size,\n                                     shuffle = False,\n                                     seed = 101,\n                                     interpolation = 'nearest',\n                                     class_mode='binary')\nval_ds = datagen.flow_from_directory(val_dir,\n                                     target_size=(img_size,img_size),\n                                     batch_size=BATCH_size,\n                                     shuffle = False,\n                                     interpolation = 'nearest',\n                                     class_mode='binary')\n\ntest_ds = datagen.flow_from_directory(test_dir,\n                                     target_size=(img_size,img_size),\n                                     batch_size=BATCH_size,\n                                     shuffle = False,\n                                     interpolation = 'nearest',\n                                     class_mode='binary')\n\nprint(train_ds.class_indices)","metadata":{"_uuid":"9d692639-8fd3-480f-8130-61766304bae0","_cell_guid":"74a7302d-2031-4118-8ba9-93ebd308bf00","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-22T14:46:50.175325Z","iopub.execute_input":"2023-08-22T14:46:50.180489Z","iopub.status.idle":"2023-08-22T14:46:53.788507Z","shell.execute_reply.started":"2023-08-22T14:46:50.180454Z","shell.execute_reply":"2023-08-22T14:46:53.787394Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"Found 69999 images belonging to 2 classes.\nFound 15000 images belonging to 2 classes.\nFound 15001 images belonging to 2 classes.\n{'0': 0, '1': 1}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# model eval","metadata":{"_uuid":"73abe5e5-58a2-4ae8-bff3-bb514c3bcd8a","_cell_guid":"85093698-6966-475e-9bec-ee633251aa60","trusted":true}},{"cell_type":"code","source":"#get kai's model from gh\n#!git clone https://github.com/luisoala/kai-class.git","metadata":{"execution":{"iopub.status.busy":"2023-08-22T14:46:53.789787Z","iopub.execute_input":"2023-08-22T14:46:53.790228Z","iopub.status.idle":"2023-08-22T14:46:53.795612Z","shell.execute_reply.started":"2023-08-22T14:46:53.790191Z","shell.execute_reply":"2023-08-22T14:46:53.794557Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"#load model\nreal_model1 = tf.saved_model.load('kai-class/real/real/seed1/network')\nreal_model2 = tf.saved_model.load('kai-class/real/real/seed2/network')\nreal_model3 = tf.saved_model.load('kai-class/real/real/seed0/network')\nsyn_model1 = tf.saved_model.load('kai-class/fake/fake/seed1/network')\nsyn_model2 = tf.saved_model.load('kai-class/fake/fake/seed2/network')\nsyn_model3 = tf.saved_model.load('kai-class/fake/fake/seed0/network')\naug_model1 = tf.saved_model.load('kai-class/augmented/augmented/seed1/network')\naug_model2 = tf.saved_model.load('kai-class/augmented/augmented/seed2/network')\naug_model3 = tf.saved_model.load('kai-class/augmented/augmented/seed0/network')\n\nrm_pred1 = real_model1.signatures[\"pred_fn\"]\nrm_pred2 = real_model2.signatures[\"pred_fn\"]\nrm_pred3 = real_model3.signatures[\"pred_fn\"]\nsyn_pred1 = syn_model1.signatures[\"pred_fn\"]\nsyn_pred2 = syn_model2.signatures[\"pred_fn\"]\nsyn_pred3 = syn_model3.signatures[\"pred_fn\"]\naug_pred1 = aug_model1.signatures[\"pred_fn\"]\naug_pred2 = aug_model2.signatures[\"pred_fn\"]\naug_pred3 = aug_model3.signatures[\"pred_fn\"]","metadata":{"_uuid":"ff3b0b67-b88a-4b2b-b739-0797612c2f5b","_cell_guid":"29d6015d-67ae-4790-9a91-280b8907ef92","execution":{"iopub.status.busy":"2023-08-22T14:46:53.796916Z","iopub.execute_input":"2023-08-22T14:46:53.797883Z","iopub.status.idle":"2023-08-22T14:47:24.939716Z","shell.execute_reply.started":"2023-08-22T14:46:53.797848Z","shell.execute_reply":"2023-08-22T14:47:24.938668Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"#get keys for pred\n#print(list(real_model.signatures.keys()))\n#print(list(syn_model.signatures.keys()))","metadata":{"execution":{"iopub.status.busy":"2023-08-22T14:47:24.941431Z","iopub.execute_input":"2023-08-22T14:47:24.941820Z","iopub.status.idle":"2023-08-22T14:47:24.948965Z","shell.execute_reply.started":"2023-08-22T14:47:24.941784Z","shell.execute_reply":"2023-08-22T14:47:24.947842Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nrm_pred = real_model.signatures[\"pred_fn\"]\nsyn_pred = syn_model.signatures[\"pred_fn\"]\naug_pred = aug_model.signatures[\"pred_fn\"]\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-22T14:47:24.950435Z","iopub.execute_input":"2023-08-22T14:47:24.950881Z","iopub.status.idle":"2023-08-22T14:47:24.961235Z","shell.execute_reply.started":"2023-08-22T14:47:24.950845Z","shell.execute_reply":"2023-08-22T14:47:24.960170Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"'\\nrm_pred = real_model.signatures[\"pred_fn\"]\\nsyn_pred = syn_model.signatures[\"pred_fn\"]\\naug_pred = aug_model.signatures[\"pred_fn\"]\\n'"},"metadata":{}}]},{"cell_type":"code","source":"def get_preds(model, ds, steps):\n    all_predictions = []\n\n    # iterate over all batches in val_ds\n    for i in range(int(steps)+1):\n        images, labels = ds.next()\n        batch_predictions = model(tf.constant(images))['output_0'].numpy()\n        all_predictions.append(batch_predictions)\n\n    # concatenate all batch predictions\n    all_predictions = np.concatenate(all_predictions, axis=0)\n    \n    return all_predictions\n","metadata":{"execution":{"iopub.status.busy":"2023-08-22T14:47:24.962675Z","iopub.execute_input":"2023-08-22T14:47:24.963331Z","iopub.status.idle":"2023-08-22T14:47:24.971096Z","shell.execute_reply.started":"2023-08-22T14:47:24.963296Z","shell.execute_reply":"2023-08-22T14:47:24.969802Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"import sklearn","metadata":{"execution":{"iopub.status.busy":"2023-08-22T14:47:24.972447Z","iopub.execute_input":"2023-08-22T14:47:24.973300Z","iopub.status.idle":"2023-08-22T14:47:24.980392Z","shell.execute_reply.started":"2023-08-22T14:47:24.973262Z","shell.execute_reply":"2023-08-22T14:47:24.979352Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"#models = [rm_pred1, rm_pred2, rm_pred3, syn_pred1, syn_pred2, syn_pred3, aug_pred1, aug_pred2, aug_pred3]\nmodels = [aug_pred2, aug_pred3]\nsplits = [train_ds, val_ds, test_ds]\nstepss = [train_step, val_step, val_step]\n#model loop\nfor model in models:\n    #print(model)\n    #data loop\n    for data, steps in zip(splits, stepss):\n        #print(data)\n        y_true = data.classes\n        #print(y_true)\n        preds = get_preds(model, data, steps)\n        y_pred=np.argmax(preds,axis=1)\n        #print(y_pred)   \n        \n        ba = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n        print(ba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# crc data","metadata":{}},{"cell_type":"code","source":"#Load the directory\nmain_path = '../input/crc-val-he-7k/CRC-VAL-HE-7K'\nsub_dir =os.listdir(main_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creat The DataFrame\nData_df=pd.DataFrame({'ID': [], 'Class':[]})\n\nfor subdir in sub_dir:\n    mypath = join(main_path,subdir)\n    files=[f for f in listdir(mypath)]\n    classes=[subdir for c in files]\n    files_df = pd.DataFrame({'ID':files, 'Class':classes})\n    Data_df = Data_df.append(files_df)\n\nData_df['Old_class'] = Data_df['Class']\n#merge classes for our setting\nData_df['Class'] = Data_df['Class'].apply(lambda x: 1 if x in ['TUM'] else 0)\nData_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Data_df.columns.tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of the Classes\nclass_of_patch = Data_df.Class.value_counts()\nprint('Distribution of classes is as followed:\\n{}'.format(class_of_patch[::-1]),'\\n','\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmain_dir = 'crc'\nos.mkdir(main_dir)\n\ntest_dir = join(main_dir,'Test')\nos.mkdir(test_dir)\n\n\nfor subdir in [\"0\", \"1\"]:\n    test_sub_dir = join(test_dir,subdir)\n    os.mkdir(test_sub_dir)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_dir = 'crc'\n\ntest_dir = join(main_dir,'Test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntest_df = Data_df.copy(deep=True)\nprint(test_df)\n\nData_df.set_index('ID', inplace=True)\n\nfor img in test_df['ID']:\n    label_old = Data_df.loc[img,'Old_class']\n    #print(label_old)\n    label_new = Data_df.loc[img,'Class']\n    source = join(main_path,label_old,img)\n    dest = join(test_dir,str(label_new),img)\n    \n    cv2_img = cv2.imread(source)\n    cv2.imwrite(dest,cv2_img)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crc_ds = datagen.flow_from_directory(test_dir, target_size= (224,224),batch_size = BATCH_size, \n                                       shuffle = False , class_mode='binary' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = models = [rm_pred1, rm_pred2, rm_pred3, syn_pred1, syn_pred2, syn_pred3, aug_pred1, aug_pred2, aug_pred3]\nsplits = [crc_ds]\nstepss = [len(test_df)/BATCH_size]\n#model loop\nfor model in models:\n    #print(model)\n    #data loop\n    for data, steps in zip(splits, stepss):\n        #print(data)\n        y_true = data.classes\n        #print(y_true)\n        preds = get_preds(model, data, steps)\n        y_pred=np.argmax(preds,axis=1)\n        #print(y_pred)\n        ba = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n        print(ba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}